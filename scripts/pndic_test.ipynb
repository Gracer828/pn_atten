{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fasttext as ft\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニュース読み込み\n",
    "paths = glob('../predict_data/*/*.csv')\n",
    "contents_list = [pd.read_csv(path,encoding='utf-8',index_col=0)[\"content\"] for path in paths]\n",
    "contents = [c for inner_list in contents_list for c in inner_list]\n",
    "\n",
    "# テキストの重複を削除\n",
    "contents = list(set(contents)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 極性辞書の読み込み\n",
    "pndic_df = pd.read_csv('../dic/pndic_2018-05-25.csv',\n",
    "                    encoding='utf-8',\n",
    "                    index_col = 0,                \n",
    "                   )\n",
    "\n",
    "# 辞書型に変換\n",
    "word_list = list(pndic_df['Word'])\n",
    "pn_list = list(pndic_df['PN'])\n",
    "pn_dict = dict(zip(word_list, pn_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 極性単語カウント>= 15の条件でニューステキストを抽出\n",
    "text_list = []\n",
    "\n",
    "for text in contents:\n",
    "    count = 0\n",
    "    for w in pn_dict.keys():\n",
    "        if w in text:\n",
    "            count += 1            \n",
    "    if count >= 15:\n",
    "        text_list.append(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スコアリング\n",
    "pnmeans_list = [np.mean([pn_dict[w]*text.count(w) for w in pn_dict.keys() if w in text]) for text in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストを分かち書き\n",
    "m = MeCab.Tagger(\"-Owakati\") \n",
    "\n",
    "news_text = [m.parse(t) for t in text_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 極性辞書評価\n",
    "dic_df = pd.DataFrame({'dic_score':pnmeans_list,\n",
    "                        'text': news_text\n",
    "                       },\n",
    "                       columns=['dic_score', 'text']\n",
    "                      )\n",
    "# PN値の昇順でソート\n",
    "dic_df = dic_df.sort_values(by='dic_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ポジネガ条件抽出\n",
    "posi_df = dic_df[dic_df.dic_score>0]\n",
    "nega_df = dic_df[dic_df.dic_score<0]\n",
    "\n",
    "text_list = list(posi_df['text'])\n",
    "p_label = [\"P\" for i in range(len(text_list))]\n",
    "posi_df['label'] = p_label\n",
    "\n",
    "text_list = list(nega_df['text'])\n",
    "n_label = [\"N\" for i in range(len(text_list))]\n",
    "nega_df['label'] = n_label\n",
    "\n",
    "concat_df = pd.concat([posi_df,nega_df])\n",
    "concat_df = concat_df.drop(\"dic_score\", axis=1)\n",
    "\n",
    "# indexを振り直す\n",
    "re_df = concat_df.reset_index(drop=True)\n",
    "re_df.to_csv(\"test_news.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
